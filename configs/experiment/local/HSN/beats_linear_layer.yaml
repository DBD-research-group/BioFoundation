# @package _global_
defaults:
  - override /module: multilabel.yaml
  - override /module/network: beats.yaml
  - override /datamodule: HSN.yaml
  - override /callbacks: default.yaml 
  - override /trainer: single_gpu.yaml
  - override /datamodule/transforms/waveform_augmentations: none.yaml
  - override /datamodule/transforms/spectrogram_augmentations: none.yaml
  - override /datamodule/transforms: bird_default_multilabel.yaml

tags: ["HSN", "BEATs", "multilabel", "no_augments", "full-finetune"]
seed: 1
train: True
test: True

logger:
  wandb:
    tags: ${tags}
    group: "HSN_train_beats"
    mode: online

module:
  optimizer:
    lr: 1e-5
    weight_decay: 5e-4
  loss:
    _target_: torch.nn.BCEWithLogitsLoss
    #_target_: birdset.modules.losses.asymmetric_loss.AsymmetricLossMultiLabel

trainer: 
  max_epochs: 100
  precision: 32
  devices: 1

datamodule:
  dataset:
    val_split: 0.1
    subset: null
    class_weights_loss: null
    class_weights_sampler: null
    classlimit: 500
    eventlimit: 5
    
  
  transforms:
    max_length: 10

  loaders:
    train: 
      batch_size: 32
      num_workers: 8
      shuffle: True
      pin_memory: False
    valid: 
      batch_size: 64
      num_workers: 8
      pin_memory: False
    test:
      batch_size: 64
      num_workers: 8
      pin_memory: False

callbacks:
  model_checkpoint:
    save_last: False
    every_n_epochs: null
    every_n_train_steps: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: "val/BCEWithLogitsLoss_epoch"
    patience: 2
    min_delta: 1e-3
    verbose: False
    check_finite: True