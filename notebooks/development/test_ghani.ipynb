{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing linear probing pipeline from Ghani\n",
    "Trying to 100% simulate ghani setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f57187e59246cf9ed8f47f4db8a249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1017 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcf4a6565244f66ba521d9335d4e269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdc4249b6ea41dbafd32c9dbce0d761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061604c1cae44591ba8539d973eb8b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'labels'],\n",
       "    num_rows: 1017\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from birdset.datamodule.beans_datamodule import BEANSDataModule\n",
    "from birdset.datamodule.base_datamodule import DatasetConfig\n",
    "\n",
    "datasetconfig = DatasetConfig(dataset_name='beans_watkins', hf_path='DBD-research-group/beans_watkins', hf_name='default')\n",
    "\n",
    "datamodule = BEANSDataModule(dataset=datasetconfig)\n",
    "dataset = datamodule._load_data()\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load model and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 22:42:50.700071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 22:42:50.700175: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 22:42:50.700209: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-17 22:42:50.708775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 22:42:52.998956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:25:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from birdset.modules.models.perch import PerchModel\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 31\n",
    "sampling_rate = 32_000 \n",
    "window_length = 5\n",
    "\n",
    "perch_network = PerchModel(num_classes=num_classes, tfhub_version=4, gpu_to_use=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Batch and Preprocess the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reprocess the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Resample function (#! Move resampler out)\n",
    "# Get embeddings\n",
    "def get_embedding(audio):\n",
    "    # Get waveform and sampling rate\n",
    "    waveform = torch.tensor(audio['array'], dtype=torch.float32)\n",
    "    dataset_sampling_rate = audio['sampling_rate']\n",
    "    # Resample audio\n",
    "    audio = resample_audio(waveform, dataset_sampling_rate, sampling_rate)\n",
    "    \n",
    "    # Zero-padding\n",
    "    audio = zero_pad(waveform)\n",
    "    \n",
    "    # Check if audio is too long \n",
    "    if waveform.shape[0] > window_length * sampling_rate:\n",
    "        return frame_and_average(waveform)    \n",
    "    else:\n",
    "        return perch_network.get_embeddings(audio)[0] # To just use embeddings not logits\n",
    "\n",
    "# Resample function\n",
    "def resample_audio(audio, orig_sr, target_sr):\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=orig_sr, new_freq=target_sr)\n",
    "    return resampler(audio)\n",
    "\n",
    "# Zero-padding function\n",
    "def zero_pad(audio):\n",
    "    desired_num_samples = window_length * sampling_rate \n",
    "    current_num_samples = audio.shape[0]\n",
    "    padding = desired_num_samples - current_num_samples\n",
    "    if padding > 0:\n",
    "        #print('padding')\n",
    "        pad_left = padding // 2\n",
    "        pad_right = padding - pad_left\n",
    "        audio = torch.nn.functional.pad(audio, (pad_left, pad_right))\n",
    "    return audio\n",
    "\n",
    "# Average multiple embeddings function\n",
    "def frame_and_average(audio):\n",
    "    # Ensure the waveform is mono\n",
    "    #if audio.size(0) > 1:\n",
    "        #print(\"What\")\n",
    "        #audio = audio.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Frame the audio\n",
    "    frame_size = window_length * sampling_rate\n",
    "    hop_size = window_length * sampling_rate\n",
    "    frames = audio.unfold(0, frame_size, hop_size)\n",
    "    \n",
    "    # Generate embeddings for each frame\n",
    "    l = []\n",
    "    for frame in frames:\n",
    "        embedding = perch_network.get_embeddings(frame) \n",
    "        l.append(embedding[0]) # To just use embeddings not logits\n",
    "    \n",
    "    embeddings = torch.stack(tuple(l))\n",
    "    \n",
    "    # Average the embeddings\n",
    "    averaged_embedding = embeddings.mean(dim=0)\n",
    "    \n",
    "    return averaged_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['audio', 'labels'])\n",
      "tensor([[[-0.0308,  0.0046, -0.0026,  ...,  0.0564,  0.2090,  0.0186]],\n",
      "\n",
      "        [[-0.0090, -0.0200, -0.0013,  ...,  0.0420,  0.2236,  0.0357]],\n",
      "\n",
      "        [[-0.0533, -0.1032, -0.0113,  ...,  0.1077,  0.1384, -0.0003]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1132, -0.0464, -0.0139,  ...,  0.0277,  0.1555,  0.0788]],\n",
      "\n",
      "        [[ 0.0108, -0.0542,  0.0072,  ...,  0.1012,  0.0907, -0.0042]],\n",
      "\n",
      "        [[-0.0511, -0.0258, -0.0234,  ...,  0.0520,  0.1342, -0.0264]]])\n",
      "tensor([28,  0, 21, 25,  1,  1,  9,  3,  8,  5, 13,  2,  8,  5, 19,  2,  3, 21,\n",
      "        20, 23, 13,  3, 10, 19, 13, 22, 20,  3,  4,  4, 26, 13])\n",
      "torch.Size([32, 1, 1280])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def preprocess(item):\n",
    "    audio = item['audio']\n",
    "    return get_embedding(audio)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_new = {}\n",
    "    audios = [preprocess(item) for item in batch]\n",
    "    batch_new['audio'] =  torch.stack(tuple(audios), dim=0)\n",
    "    batch_new['labels'] = torch.tensor([item['labels'] for item in batch])\n",
    "    return batch_new\n",
    "\n",
    "train_loader = DataLoader(dataset['train'], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(dataset['valid'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Example of iterating through the DataLoader\n",
    "for batch in train_loader:\n",
    "    print(batch.keys())\n",
    "    print(batch['audio'])\n",
    "    print(batch['labels'])\n",
    "    print(batch['audio'].shape)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "gpu_id = 1  # Change this to the ID of the GPU you want to use\n",
    "device = torch.device(f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}') #! Not working right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 3.4328, Val Loss: 3.4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 3.4272, Val Loss: 3.4258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 32/32 [00:34<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 3.4215, Val Loss: 3.4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 3.4161, Val Loss: 3.4155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 3.4105, Val Loss: 3.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 3.4050, Val Loss: 3.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 3.3996, Val Loss: 3.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 32/32 [00:33<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 3.3943, Val Loss: 3.3954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 3.3887, Val Loss: 3.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 3.3834, Val Loss: 3.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 3.3781, Val Loss: 3.3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 32/32 [00:33<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 3.3728, Val Loss: 3.3757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 3.3675, Val Loss: 3.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 32/32 [00:35<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 3.3621, Val Loss: 3.3660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 3.3568, Val Loss: 3.3612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 3.3517, Val Loss: 3.3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 3.3465, Val Loss: 3.3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 3.3414, Val Loss: 3.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 3.3360, Val Loss: 3.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 3.3311, Val Loss: 3.3372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 3.3257, Val Loss: 3.3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 3.3207, Val Loss: 3.3278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 3.3154, Val Loss: 3.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 3.3104, Val Loss: 3.3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 3.3053, Val Loss: 3.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 3.3003, Val Loss: 3.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 3.2952, Val Loss: 3.3045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 3.2903, Val Loss: 3.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 32/32 [00:35<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 3.2852, Val Loss: 3.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 32/32 [00:35<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 3.2803, Val Loss: 3.2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 3.2750, Val Loss: 3.2862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 3.2702, Val Loss: 3.2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 3.2656, Val Loss: 3.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 32/32 [00:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 3.2606, Val Loss: 3.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 32/32 [00:35<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 3.2558, Val Loss: 3.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 3.2508, Val Loss: 3.2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 3.2459, Val Loss: 3.2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 3.2410, Val Loss: 3.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 3.2361, Val Loss: 3.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 32/32 [00:35<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 3.2314, Val Loss: 3.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 3.2265, Val Loss: 3.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 3.2219, Val Loss: 3.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 3.2173, Val Loss: 3.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 3.2124, Val Loss: 3.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 3.2077, Val Loss: 3.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 3.2027, Val Loss: 3.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 3.1983, Val Loss: 3.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 32/32 [00:32<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 3.1932, Val Loss: 3.2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 3.1888, Val Loss: 3.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 32/32 [00:35<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 3.1839, Val Loss: 3.2028\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your classifier model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "class Classifier2(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "# Set the input size and number of classes\n",
    "input_size = 1280\n",
    "\n",
    "# Create an instance of your classifier model\n",
    "classifier = Classifier(input_size, num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 50  \n",
    "\n",
    "early_stopping_patience = 5\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = batch['audio'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validate the model (assuming you have a validation loader)\n",
    "    classifier.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['audio'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the best model weights if necessary\n",
    "        torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9358636140823364\n",
      "F1: 0.32743361592292786\n",
      "T1Accuracy: 0.32743361592292786\n",
      "T3Accuracy: 0.6342182755470276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import torchmetrics\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "perch_network.eval()\n",
    "\n",
    "\n",
    "# Initialize the metrics\n",
    "metrics = torchmetrics.MetricCollection({\n",
    "    'T1Accuracy': torchmetrics.Accuracy(\n",
    "        task=\"multiclass\",\n",
    "        num_classes=num_classes,\n",
    "        top_k=1\n",
    "    ),\n",
    "    'T3Accuracy': torchmetrics.Accuracy(\n",
    "        task=\"multiclass\",\n",
    "        num_classes=num_classes,\n",
    "        top_k=3\n",
    "    ),\n",
    "    'AUROC': torchmetrics.AUROC(\n",
    "        task=\"multiclass\",\n",
    "        num_classes=num_classes,\n",
    "        average='macro'\n",
    "    ),\n",
    "    'F1': torchmetrics.F1Score(\n",
    "        task=\"multiclass\",\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "}).to(device)\n",
    "\n",
    "# Iterate over the test_loader\n",
    "for batch in test_loader:\n",
    "    # Forward pass\n",
    "    inputs = batch['audio'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "    \n",
    "    # Update the metrics\n",
    "    metrics(outputs, labels)\n",
    "\n",
    "# Compute and print the metric values\n",
    "metric_values = metrics.compute()\n",
    "for metric_name, metric_value in metric_values.items():\n",
    "    print(f\"{metric_name}: {metric_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
