{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset, Audio, DatasetInfo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset parquet (/home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata1k_ogg_nodecode-2458d6d017e1feb5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2356ba405e094797ab5cb3e446e6b762",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "birdset1k = load_dataset(\"DBD-research-group/na_metadata1k_ogg_nodecode\") \n",
                "birdset1k = birdset1k.cast_column(\n",
                "    column=\"audio\",\n",
                "    feature=Audio(\n",
                "        sampling_rate=32_000,\n",
                "        mono=True,\n",
                "        decode=True\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "birdset1k[\"train\"].info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['lat', 'lng', 'type', 'sex', 'primary', 'continent', 'secondary', 'audio', 'ebird_code', 'id', 'file'],\n",
                            "        num_rows: 800\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['lat', 'lng', 'type', 'sex', 'primary', 'continent', 'secondary', 'audio', 'ebird_code', 'id', 'file'],\n",
                            "        num_rows: 200\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'train': [{'filename': '/home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata1k_ogg_nodecode-2458d6d017e1feb5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/parquet-train.arrow'}],\n",
                            " 'test': [{'filename': '/home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata1k_ogg_nodecode-2458d6d017e1feb5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/parquet-test.arrow'}]}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k.cache_files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'train': 800, 'test': 200}"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k.num_rows"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'train': ['lat',\n",
                            "  'lng',\n",
                            "  'type',\n",
                            "  'sex',\n",
                            "  'primary',\n",
                            "  'continent',\n",
                            "  'secondary',\n",
                            "  'audio',\n",
                            "  'ebird_code',\n",
                            "  'id',\n",
                            "  'file'],\n",
                            " 'test': ['lat',\n",
                            "  'lng',\n",
                            "  'type',\n",
                            "  'sex',\n",
                            "  'primary',\n",
                            "  'continent',\n",
                            "  'secondary',\n",
                            "  'audio',\n",
                            "  'ebird_code',\n",
                            "  'id',\n",
                            "  'file']}"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k.column_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'train': (800, 11), 'test': (200, 11)}"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'lat': Value(dtype='float64', id=None),\n",
                            " 'lng': Value(dtype='float64', id=None),\n",
                            " 'type': Value(dtype='string', id=None),\n",
                            " 'sex': Value(dtype='string', id=None),\n",
                            " 'primary': ClassLabel(names=['acanthis hornemanni', 'accipiter cooperii', 'actitis macularius', 'aegolius acadicus', 'aegolius funereus', 'agelaius phoeniceus', 'aimophila rufescens', 'aimophila ruficeps', 'alopochen aegyptiaca', 'amazilia rutila', 'amazilia tzacatl', 'amazilia yucatanensis', 'amazona autumnalis', 'amazona finschi', 'amazona guatemalae', 'amazona leucocephala', 'amblycercus holosericeus', 'ammodramus savannarum', 'ammospiza leconteii', 'ammospiza nelsoni', 'amphispiza bilineata', 'anabacerthia variegaticeps', 'anas carolinensis', 'anas platyrhynchos', 'anser caerulescens', 'anser rossii', 'antigone canadensis', 'antrostomus arizonae', 'antrostomus ridgwayi', 'antrostomus saturatus', 'antrostomus vociferus', 'aphelocoma unicolor', 'aphelocoma wollweberi', 'aphelocoma woodhouseii', 'ara militaris', 'archilochus alexandri', 'ardea alba', 'arenaria interpres', 'arremon virenticeps', 'artemisiospiza belli', 'aspatha gularis', 'athene cunicularia', 'atlapetes albinucha', 'atlapetes tibialis', 'attila spadiceus', 'aulacorhynchus prasinus', 'auriparus flaviceps', 'aythya marila', 'baeolophus atricristatus', 'baeolophus bicolor', 'baeolophus inornatus', 'baeolophus ridgwayi', 'basileuterus lachrymosus', 'basileuterus melanotis', 'basilinna leucotis', 'bombycilla garrulus', 'botaurus lentiginosus', 'brachyramphus marmoratus', 'branta bernicla', 'branta canadensis', 'bubo virginianus', 'buteo brachyurus', 'buteo jamaicensis', 'cacicus cela', 'calcarius lapponicus', 'calidris alpina', 'calidris bairdii', 'calidris himantopus', 'calidris melanotos', 'calidris minutilla', 'calidris pusilla', 'callipepla californica', 'callipepla douglasii', 'callipepla gambelii', 'calocitta colliei', 'calocitta formosa', 'calothorax lucifer', 'calypte anna', 'campephilus guatemalensis', 'campylorhynchus brunneicapillus', 'campylorhynchus gularis', 'campylorhynchus jocosus', 'campylorhynchus zonatus', 'cantorchilus elutus', 'cantorchilus modestus', 'cantorchilus nigricapillus', 'cantorchilus semibadius', 'cantorchilus thoracicus', 'cardellina canadensis', 'cardellina pusilla', 'cardellina rubrifrons', 'cardinalis cardinalis', 'cassiculus melanicterus', 'catharus aurantiirostris', 'catharus fuscater', 'catharus fuscescens', 'catharus gracilirostris', 'catharus ustulatus', 'catherpes mexicanus', 'centronyx bairdii', 'centronyx henslowii', 'cercomacroides tyrannina', 'certhia americana', 'chaetura pelagica', 'chamaea fasciata', 'charadrius nivosus', 'charadrius vociferus', 'chiroxiphia lanceolata', 'chlidonias niger', 'chlorestes candida', 'chlorodrepanis flava', 'chlorophonia elegantissima', 'chlorospingus flavopectus', 'chlorothraupis carmioli', 'chondestes grammacus', 'chordeiles gundlachii', 'chordeiles minor', 'cinclus mexicanus', 'cistothorus palustris', 'cistothorus stellaris', 'coccyzus americanus', 'coccyzus erythropthalmus', 'coereba flaveola', 'colaptes auratus', 'colinus virginianus', 'columbina inca', 'columbina passerina', 'contopus cooperi', 'contopus pertinax', 'contopus sordidulus', 'contopus virens', 'corthylio calendula', 'corvus brachyrhynchos', 'corvus corax', 'corvus ossifragus', 'corvus sinaloae', 'crax rubra', 'crotophaga ani', 'cyanocitta cristata', 'cyanocitta stelleri', 'cyanocompsa parellina', 'cyanocorax luxuosus', 'cyanocorax melanocyaneus', 'cyanoloxia cyanoides', 'cyclarhis gujanensis', 'cynanthus latirostris', 'cyphorhinus phaeocephalus', 'dendrocolaptes sanctithomae', 'dendrortyx leucophrys', 'dives dives', 'dolichonyx oryzivorus', 'drepanis coccinea', 'dryobates pubescens', 'dryobates scalaris', 'dryocopus lineatus', 'dryocopus pileatus', 'dumetella carolinensis', 'egretta caerulea', 'egretta rufescens', 'egretta thula', 'egretta tricolor', 'electron platyrhynchum', 'empidonax albigularis', 'empidonax alnorum', 'empidonax difficilis', 'empidonax flaviventris', 'empidonax minimus', 'empidonax oberholseri', 'empidonax occidentalis', 'empidonax virescens', 'epinecrophylla fulviventris', 'eremophila alpestris', 'eugenes fulgens', 'euphagus carolinus', 'euphagus cyanocephalus', 'euphonia affinis', 'euphonia hirundinacea', 'euphonia laniirostris', 'falco columbarius', 'falco sparverius', 'forpus cyanopygius', 'fulica americana', 'gallinula galeata', 'gallus gallus', 'gavia stellata', 'geococcyx californianus', 'geothlypis formosa', 'geothlypis philadelphia', 'geothlypis speciosa', 'geothlypis tolmiei', 'geothlypis trichas', 'glaucidium brasilianum', 'glaucidium californicum', 'glaucidium gnoma', 'glaucidium palmarum', 'habia atrimaxillaris', 'habia fuscicauda', 'habia rubica', 'haematopus bachmani', 'haemorhous cassinii', 'haemorhous mexicanus', 'haemorhous purpureus', 'haliaeetus leucocephalus', 'hemignathus wilsoni', 'henicorhina leucosticta', 'herpetotheres cachinnans', 'himantopus mexicanus', 'himatione sanguinea', 'hirundo rustica', 'hylocichla mustelina', 'hylopezus perspicillatus', 'icteria virens', 'icterus galbula', 'icterus parisorum', 'icterus pustulatus', 'ixoreus naevius', 'jacana spinosa', 'junco hyemalis', 'lampornis clemenciae', 'larus brachyrhynchus', 'larus californicus', 'larus delawarensis', 'laterallus albigularis', 'laterallus exilis', 'laterallus jamaicensis', 'laterallus ruber', 'legatus leucophaius', 'leiothlypis celata', 'leiothlypis luciae', 'leiothlypis peregrina', 'leiothlypis ruficapilla', 'leptotila cassinii', 'leucolia violiceps', 'leuconotopicus albolarvatus', 'leuconotopicus villosus', 'leucophaeus atricilla', 'limnodromus scolopaceus', 'lipaugus unirufus', 'lonchura punctulata', 'loxia curvirostra', 'loxia leucoptera', 'loxia sinesciuris', 'loxops mana', 'manacus candei', 'manacus vitellinus', 'mareca americana', 'mareca strepera', 'margarops fuscatus', 'megaceryle alcyon', 'megarynchus pitangua', 'megascops guatemalae', 'megascops kennicottii', 'megascops trichopsis', 'melanerpes carolinus', 'melanerpes chrysogenys', 'melanerpes formicivorus', 'melanitta deglandi', 'melanitta perspicillata', 'melanotis caerulescens', 'meleagris gallopavo', 'melospiza georgiana', 'melospiza melodia', 'melozone aberti', 'melozone albicollis', 'melozone crissalis', 'melozone fusca', 'melozone kieneri', 'mergus serrator', 'micrastur semitorquatus', 'microbates cinereiventris', 'mimus gilvus', 'mimus polyglottos', 'mniotilta varia', 'molothrus aeneus', 'momotus mexicanus', 'morococcyx erythropygus', 'myadestes occidentalis', 'myadestes townsendi', 'mycteria americana', 'myiarchus cinerascens', 'myiarchus crinitus', 'myiarchus nuttingi', 'myiarchus sagrae', 'myioborus pictus', 'myioborus torquatus', 'myiodynastes luteiventris', 'myiopagis viridicata', 'myiopsitta monachus', 'myiozetetes similis', 'myrmotherula axillaris', 'nannopterum brasilianum', 'nucifraga columbiana', 'numenius hudsonicus', 'nyctidromus albicollis', 'nyctiphrynus mcleodii', 'odontophorus guttatus', 'odontophorus melanotis', 'oreortyx pictus', 'oreoscoptes montanus', 'oreothlypis superciliosa', 'ortalis poliocephala', 'ortalis wagleri', 'oxyura jamaicensis', 'pachyramphus aglaiae', 'pachysylvia decurtata', 'pandion haliaetus', 'pardirallus maculatus', 'parkesia motacilla', 'parkesia noveboracensis', 'passer domesticus', 'passerculus sandwichensis', 'passerella iliaca', 'passerella megarhyncha', 'passerella schistacea', 'passerella unalaschcensis', 'passerina amoena', 'passerina caerulea', 'passerina ciris', 'passerina cyanea', 'passerina rositae', 'patagioenas fasciata', 'patagioenas flavirostris', 'perdix perdix', 'perisoreus canadensis', 'petrochelidon pyrrhonota', 'peucaea aestivalis', 'peucaea botterii', 'peucaea carpalis', 'peucaea cassinii', 'peucaea mystacalis', 'peucaea ruficauda', 'phaethornis longirostris', 'phalaropus fulicarius', 'phalaropus tricolor', 'pharomachrus mocinno', 'pheucticus ludovicianus', 'pheucticus melanocephalus', 'pheucticus tibialis', 'pheugopedius atrogularis', 'pheugopedius maculipectus', 'phoebastria immutabilis', 'piaya cayana', 'pica hudsonia', 'picoides arcticus', 'picoides dorsalis', 'pinicola enucleator', 'pipilo chlorurus', 'pipilo erythrophthalmus', 'pipilo maculatus', 'piranga hepatica', 'piranga ludoviciana', 'piranga olivacea', 'piranga rubra', 'pitangus sulphuratus', 'plectrophenax nivalis', 'pluvialis dominica', 'pluvialis squatarola', 'podilymbus podiceps', 'poecile atricapillus', 'poecile carolinensis', 'poecile gambeli', 'poecile hudsonicus', 'polioptila albiloris', 'polioptila caerulea', 'polioptila melanura', 'polioptila nigriceps', 'pooecetes gramineus', 'porphyrio martinica', 'porzana carolina', 'progne subis', 'psaltriparus minimus', 'psarocolius montezuma', 'psarocolius wagleri', 'psittacara holochlorus', 'pterodroma hypoleuca', 'pyrilia haematotis', 'pyrocephalus obscurus', 'quiscalus major', 'quiscalus mexicanus', 'rallus crepitans', 'rallus elegans', 'rallus limicola', 'rallus obsoletus', 'ramphocaenus melanurus', 'ramphocelus dimidiatus', 'ramphocelus passerinii', 'ramphocelus sanguinolentus', 'ramphotrigon flammulatum', 'regulus satrapa', 'rhynchophanes mccownii', 'riparia riparia', 'rupornis magnirostris', 'salpinctes obsoletus', 'saltator atriceps', 'saltator grandis', 'sayornis nigricans', 'sayornis phoebe', 'schiffornis veraepacis', 'scolopax minor', 'scytalopus argentifrons', 'seiurus aurocapilla', 'selasphorus calliope', 'selasphorus platycercus', 'selasphorus rufus', 'setophaga aestiva', 'setophaga americana', 'setophaga auduboni', 'setophaga caerulescens', 'setophaga cerulea', 'setophaga citrina', 'setophaga coronata', 'setophaga discolor', 'setophaga dominica', 'setophaga fusca', 'setophaga graciae', 'setophaga kirtlandii', 'setophaga magnolia', 'setophaga nigrescens', 'setophaga pensylvanica', 'setophaga petechia', 'setophaga pitiayumi', 'setophaga pityophila', 'setophaga ruticilla', 'setophaga striata', 'setophaga townsendi', 'setophaga virens', 'sialia sialis', 'sitta canadensis', 'sitta pygmaea', 'spatula cyanoptera', 'sphyrapicus thyroideus', 'spindalis zena', 'spinus lawrencei', 'spinus pinus', 'spinus psaltria', 'spinus tristis', 'spiza americana', 'spizella breweri', 'spizella pallida', 'spizella passerina', 'spizelloides arborea', 'sporophila torqueola', 'stelgidopteryx serripennis', 'sterna dougallii', 'sterna forsteri', 'sterna hirundo', 'sternula antillarum', 'stilpnia larvata', 'strix varia', 'sturnella magna', 'sturnella neglecta', 'synallaxis albescens', 'synallaxis erythrothorax', 'tachycineta bicolor', 'tachycineta thalassina', 'tapera naevia', 'taraba major', 'thalasseus elegans', 'thalasseus maximus', 'thamnistes anabatinus', 'thamnophilus bridgesi', 'thamnophilus doliatus', 'thryomanes bewickii', 'thryophilus pleurostictus', 'thryophilus rufalbus', 'thryophilus sinaloa', 'thryothorus ludovicianus', 'tiaris olivaceus', 'todus mexicanus', 'tolmomyias flaviventris', 'tolmomyias sulphurescens', 'toxostoma crissale', 'toxostoma curvirostre', 'toxostoma lecontei', 'toxostoma longirostre', 'toxostoma ocellatum', 'toxostoma redivivum', 'toxostoma rufum', 'tringa melanoleuca', 'tringa semipalmata', 'tringa solitaria', 'troglodytes aedon', 'troglodytes hiemalis', 'troglodytes pacificus', 'troglodytes rufociliatus', 'trogon caligatus', 'trogon collaris', 'trogon elegans', 'tunchiornis ochraceiceps', 'turdus grayi', 'turdus migratorius', 'turdus nigrescens', 'turdus rufopalliatus', 'tympanuchus phasianellus', 'tyrannus couchii', 'tyrannus dominicensis', 'tyrannus melancholicus', 'tyrannus tyrannus', 'tyrannus verticalis', 'tyrannus vociferans', 'vermivora cyanoptera', 'vireo altiloquus', 'vireo bellii', 'vireo cassinii', 'vireo flavifrons', 'vireo flavoviridis', 'vireo gilvus', 'vireo griseus', 'vireo huttoni', 'vireo hypochryseus', 'vireo olivaceus', 'vireo pallens', 'vireo philadelphicus', 'vireo plumbeus', 'vireo solitarius', 'xanthocephalus xanthocephalus', 'xiphocolaptes promeropirhynchus', 'xiphorhynchus flavigaster', 'xiphorhynchus susurrans', 'zeledonia coronata', 'zenaida asiatica', 'zenaida macroura', 'zentrygon albifacies', 'zonotrichia albicollis', 'zonotrichia atricapilla', 'zonotrichia leucophrys', 'zonotrichia querula'], id=None),\n",
                            " 'continent': Value(dtype='string', id=None),\n",
                            " 'secondary': Value(dtype='string', id=None),\n",
                            " 'audio': Audio(sampling_rate=32000, mono=True, decode=True, id=None),\n",
                            " 'ebird_code': Value(dtype='string', id=None),\n",
                            " 'id': Value(dtype='int64', id=None),\n",
                            " 'file': Value(dtype='string', id=None)}"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k[\"train\"].features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'path': 'XC146305.ogg',\n",
                            " 'array': array([ 2.25619879e-05,  3.81759601e-05,  4.19990392e-05, ...,\n",
                            "        -4.22009546e-03,  5.75777609e-03,  5.16055990e-03]),\n",
                            " 'sampling_rate': 32000}"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# decode was turned off in preprocessing\n",
                "birdset1k[\"train\"][0][\"audio\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**set transform**\n",
                "- applied right before returning objects in __getitem__\n",
                "- can be applied to specific columns but can also return the unformatted ones!\n",
                "- cast_column is very similar (but introduced as .astype of a column)\n",
                "- set_format = set the __getitem__ return format \n",
                "# "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "birdset1k_audio = birdset1k.select_columns(['audio', 'primary'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'primary': 485,\n",
                            " 'audio': {'path': 'XC146305.ogg',\n",
                            "  'array': array([ 2.25619879e-05,  3.81759601e-05,  4.19990392e-05, ...,\n",
                            "         -4.22009546e-03,  5.75777609e-03,  5.16055990e-03]),\n",
                            "  'sampling_rate': 32000}}"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k_audio[\"train\"][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "birdset1k_audio.set_format(type='pt')\n",
                "\n",
                "# also works with \"with_format\" that returns a new object on-the-fly (could be better!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'primary': tensor(485),\n",
                            " 'audio': {'path': 'XC146305.ogg',\n",
                            "  'array': tensor([ 2.2562e-05,  3.8176e-05,  4.1999e-05,  ..., -4.2201e-03,\n",
                            "           5.7578e-03,  5.1606e-03]),\n",
                            "  'sampling_rate': tensor(32000)}}"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k_audio[\"train\"][0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Load Data**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 800/800 [02:11<00:00,  6.10it/s]\n"
                    ]
                }
            ],
            "source": [
                "for i in tqdm(birdset1k_audio[\"train\"]):\n",
                "    pass\n",
                "\n",
                "# running through 800 training instances took 2 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "with dataloader\n",
                "\n",
                "- padding is neccessary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": [
                "birdset1k_audio.set_format(type='np')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import BatchFeature\n",
                "from transformers import SequenceFeatureExtractor\n",
                "import numpy as np \n",
                "# we could incorporate some kind of event detector in the customfeatureextractor\n",
                "\n",
                "class CustomFeatureExtractor(SequenceFeatureExtractor):\n",
                "    model_input_names = [\"input_values\"]\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        feature_size=1,\n",
                "        sampling_rate=32_000,\n",
                "        padding_value=0.0,\n",
                "        return_attention_mask=False\n",
                "    ):\n",
                "        # initialize sequencefeatureextractor\n",
                "        super().__init__(feature_size=feature_size, sampling_rate=sampling_rate, padding_value=padding_value)\n",
                "        self.return_attention_mask = return_attention_mask\n",
                "\n",
                "    def __call__(\n",
                "        self, \n",
                "        raw_audio,\n",
                "        padding = False, \n",
                "        max_length = None,\n",
                "        truncation = False, \n",
                "        return_tensors = None,\n",
                "        sampling_rate = None\n",
                "    ) -> BatchFeature:\n",
                "        \n",
                "        # control/check sampling rate \n",
                "        if self.sampling_rate is not None: \n",
                "            if sampling_rate != self.sampling_rate:\n",
                "                raise ValueError(\n",
                "                    f\"The model corresponding to this feature extractor: {self} was trained using a sampling rate of\"\n",
                "                    f\"{self.sampling_rate}. Make sure that the provided `raw_audio`input was sampled with\"\n",
                "                    f\"{self.sampling_rate} and not {sampling_rate}.\"\n",
                "                )\n",
                "        else:\n",
                "            print( \"It is strongly recommended to pass the ``sampling_rate`` argument to this function. \\\n",
                "                    Failing to do so can result in silent errors that might be hard to debug.\")\n",
                "        # check batch input\n",
                "        is_batched_numpy = isinstance(raw_audio, np.ndarray) and len(raw_audio.shape) > 1\n",
                "        is_batched = is_batched_numpy or (\n",
                "            isinstance(raw_audio, (list, tuple)) and (isinstance(raw_audio[0], (np.ndarray, tuple, list)))\n",
                "        )\n",
                "\n",
                "        if not is_batched:\n",
                "            raw_audio = [raw_audio]\n",
                "\n",
                "        encoded_inputs = BatchFeature({\"input_values\": raw_audio})\n",
                "\n",
                "        padded_inputs = self.pad(\n",
                "            encoded_inputs,\n",
                "            padding=padding,\n",
                "            max_length=max_length,\n",
                "            return_attention_mask=None,\n",
                "            truncation=truncation\n",
                "        )\n",
                "        # return_to_tensors comes from: transformers/birdset/transformers/feature_extraction_utils.py\n",
                "        if return_tensors is not None:\n",
                "            padded_inputs = padded_inputs.convert_to_tensors(return_tensors)\n",
                "                \n",
                "        return padded_inputs "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- custom feature extractor does not work when birdset1k_audio.set_format(type='pt')\n",
                "- can be done via .map\n",
                "- !! map could also load in all data and then detect events with equal lengths and choose this for the complete dataset\n",
                "It is helpful to understand how this works, so you can come up with your own ways to use batch mapping. At this point, you may be wondering how you can control the size of the generated datamodule. The answer is: the mapped function does not have to return an output batch of the same size.\n",
                "\n",
                "In other words, your mapped function input can be a batch of size N and return a batch of size M. The output M can be greater than or less than N. **This means you can concatenate your examples, divide it up, and even add more examples!**\n",
                "\n",
                "from datasets import Dataset\n",
                "\n",
                "dataset = Dataset.from_dict({\"a\": [0, 1, 2]})\n",
                "\n",
                "dataset_with_duplicates = datamodule.map(lambda batch: {\"b\": batch[\"a\"] * 2}, remove_columns=[\"a\"], batched=True)\n",
                "\n",
                "len(dataset_with_duplicates)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'path': 'XC146305.ogg',\n",
                            " 'array': array([ 2.25619879e-05,  3.81759601e-05,  4.19990392e-05, ...,\n",
                            "        -4.22009546e-03,  5.75777609e-03,  5.16055990e-03]),\n",
                            " 'sampling_rate': 32000}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset1k_audio[\"train\"][0][\"audio\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6bd1c58cb56b4171a15ca1e5413084f0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Exception ignored from cffi callback <function SoundFile._init_virtual_io.<locals>.vio_read at 0x7ff7e2347430>:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/lukas/miniconda3/envs/dal-toolbox/lib/python3.9/site-packages/soundfile.py\", line 1244, in vio_read\n",
                        "    try:\n",
                        "KeyboardInterrupt: \n"
                    ]
                }
            ],
            "source": [
                "feature_extractor = CustomFeatureExtractor()\n",
                "\n",
                "def preprocess_function(samples):\n",
                "    audio_arrays = [x[\"array\"] for x in samples[\"audio\"]]\n",
                "    inputs = feature_extractor(\n",
                "        audio_arrays,\n",
                "        sampling_rate=feature_extractor.sampling_rate,\n",
                "        padding=True,\n",
                "        max_length=16_000*5,\n",
                "        truncation=True,\n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "    return inputs\n",
                "\n",
                "\n",
                "encoded_birdset = birdset1k_audio.map(\n",
                "    preprocess_function,\n",
                "    remove_columns=['audio'],\n",
                "    batched=True,\n",
                "    batch_size=100\n",
                ")\n",
                "\n",
                "# truncate and pad"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'encoded_birdset' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_birdset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'encoded_birdset' is not defined"
                    ]
                }
            ],
            "source": [
                "encoded_birdset[\"train\"][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "torch.cuda.device_count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataloader = DataLoader(\n",
                "    encoded_birdset[\"train\"],\n",
                "    batch_size=16,\n",
                "    shuffle=False,\n",
                "    num_workers=4,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([16, 80000])"
                        ]
                    },
                    "execution_count": 66,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(dataloader))[\"input_values\"].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 2.2562e-05,  3.8176e-05,  4.1999e-05,  ...,  1.3886e-02,\n",
                            "          1.5060e-02,  8.7285e-03],\n",
                            "        [ 3.7719e-07,  2.6892e-08, -3.3760e-08,  ...,  3.0991e-03,\n",
                            "         -4.7870e-03, -8.9598e-03],\n",
                            "        [ 1.1176e-08, -3.4459e-08, -5.5879e-09,  ..., -3.4147e-02,\n",
                            "         -3.4990e-02, -3.4313e-02],\n",
                            "        ...,\n",
                            "        [ 1.0459e-11,  5.6843e-12,  3.1832e-12,  ..., -8.9108e-04,\n",
                            "         -4.2660e-04, -4.8647e-03],\n",
                            "        [ 1.1921e-07, -6.2864e-08, -3.5856e-08,  ...,  2.0346e-34,\n",
                            "          2.0346e-34,  2.0346e-34],\n",
                            "        [-4.4518e-05, -4.2392e-05, -1.9335e-05,  ..., -2.4559e-02,\n",
                            "          3.0974e-03,  2.5544e-02]])"
                        ]
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(dataloader))[\"input_values\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 50/50 [00:01<00:00, 30.06it/s]\n"
                    ]
                }
            ],
            "source": [
                "for _ in tqdm(dataloader):\n",
                "    pass\n",
                "\n",
                "# 1.6 seconds "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'path': 'XC146305.ogg',\n",
                            " 'array': array([ 2.25619879e-05,  3.81759601e-05,  4.19990392e-05, ...,\n",
                            "        -4.22009546e-03,  5.75777609e-03,  5.16055990e-03]),\n",
                            " 'sampling_rate': 32000}"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# without .map\n",
                "birdset1k_audio[\"train\"][0][\"audio\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import DataCollatorWithPadding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass\n",
                "from typing import Any\n",
                "from transformers import BatchFeature\n",
                "\n",
                "@dataclass\n",
                "class CustomCollatorWithPadding:\n",
                "\n",
                "    feature_extractor: Any\n",
                "    padding: bool = True\n",
                "    truncation: bool = True\n",
                "    max_length: int = None\n",
                "    return_tensors: str = \"pt\"\n",
                "    preprocessed: bool=False\n",
                "\n",
                "    def __call__(self, batch):\n",
                "\n",
                "        # preprocessed means that the .map function was applied\n",
                "        # here, the feature extractor is only used for padding\n",
                "        if self.preprocessed:\n",
                "            batch = self.feature_extractor.pad(\n",
                "                batch,\n",
                "                padding=self.padding,\n",
                "                max_length=self.max_length,\n",
                "                truncation=self.truncation,\n",
                "                return_tensors=self.return_tensors,\n",
                "                return_attention_mask = None\n",
                "            )\n",
                "\n",
                "        # here, we first have to format the input and then pad it\n",
                "        # note that everything regarding resampling is not implemented here    \n",
                "        else:\n",
                "            audio_arrays = [x[\"audio\"][\"array\"] for x in batch]\n",
                "            labels = [x[\"primary\"] for x in batch]\n",
                "\n",
                "            # batch feature is just a dictionary\n",
                "            encoded_inputs = BatchFeature({\"input_values\": audio_arrays})\n",
                "            batch = {**encoded_inputs, \"labels\": labels}\n",
                "\n",
                "            batch = self.feature_extractor.pad(\n",
                "                batch,\n",
                "                padding=self.padding,\n",
                "                max_length=self.max_length,\n",
                "                truncation=self.truncation,\n",
                "                return_tensors=self.return_tensors,\n",
                "                return_attention_mask = None\n",
                "            )\n",
                "\n",
                "        if \"label\" in batch: \n",
                "            batch[\"labels\"] = batch[\"label\"]\n",
                "            del batch[\"label\"]\n",
                "\n",
                "        if \"target\" in batch:\n",
                "            batch[\"labels\"] = batch[\"target\"]\n",
                "            del batch[\"target\"]\n",
                "        \n",
                "        if \"primary\" in batch:\n",
                "            batch[\"labels\"] = batch[\"primary\"]\n",
                "            del batch[\"primary\"]\n",
                "\n",
                "        \n",
                "        return batch\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_extractor = CustomFeatureExtractor()\n",
                "dataloader = DataLoader(\n",
                "    birdset1k_audio[\"train\"],\n",
                "    collate_fn=CustomCollatorWithPadding(\n",
                "        feature_extractor,\n",
                "        padding='longest',\n",
                "        return_tensors=\"pt\",\n",
                "        truncation=False        \n",
                "    ),\n",
                "    batch_size=16,\n",
                "    shuffle=False,\n",
                "    num_workers=4,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'input_values': tensor([[ 2.2562e-05,  3.8176e-05,  4.1999e-05,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [ 3.7719e-07,  2.6892e-08, -3.3760e-08,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [ 1.1176e-08, -3.4459e-08, -5.5879e-09,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        ...,\n",
                            "        [ 1.0459e-11,  5.6843e-12,  3.1832e-12,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [ 1.1921e-07, -6.2864e-08, -3.5856e-08,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [-4.4518e-05, -4.2392e-05, -1.9335e-05,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00]]), 'labels': tensor([485, 391, 191, 273,   6, 187, 513, 127, 427, 219, 180, 363, 489, 196,\n",
                            "        116,  38])}"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(dataloader))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 50/50 [00:44<00:00,  1.11it/s]\n"
                    ]
                }
            ],
            "source": [
                "for batch in tqdm(dataloader):\n",
                "    pass\n",
                "\n",
                "# takes 44 seconds"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test for Birdset5k"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset, Audio, DatasetInfo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset parquet (/home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata5k_ogg_nodecode-de5164d492ad6e9e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "57af8abcb2544d78b1bd3030498bef19",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "birdset5k = load_dataset(\"DBD-research-group/na_metadata5k_ogg_nodecode\") \n",
                "birdset5k = birdset5k.cast_column(\n",
                "    column=\"audio\",\n",
                "    feature=Audio(\n",
                "        sampling_rate=32_000,\n",
                "        mono=True,\n",
                "        decode=True\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "birdset5k_audio = birdset5k.select_columns(['audio', 'primary'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['primary', 'audio'],\n",
                            "        num_rows: 4316\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['primary', 'audio'],\n",
                            "        num_rows: 1080\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset5k_audio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'primary': 12,\n",
                            " 'audio': {'path': 'XC402197.ogg',\n",
                            "  'array': array([ 8.73114914e-11, -1.45519152e-10, -5.38420863e-10, ...,\n",
                            "          2.28490215e-03,  1.52546330e-03,  2.12723855e-04]),\n",
                            "  'sampling_rate': 32000}}"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset5k_audio[\"train\"][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 4316/4316 [11:22<00:00,  6.33it/s]\n"
                    ]
                }
            ],
            "source": [
                "for instance in tqdm(birdset5k_audio[\"train\"]):\n",
                "    pass\n",
                "\n",
                "# running through 800 training instances took 2 minutes\n",
                "# now we have 5.395 times the data with 4316 training instances\n",
                "# it took 11 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**With Mapping**\n",
                "\n",
                "- idea is to use this as event detection + transformation to spectrograms\n",
                "- set_transform could also be used instead of cast_column to load only parts of the audio file if required"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import BatchFeature\n",
                "from transformers import SequenceFeatureExtractor\n",
                "import numpy as np \n",
                "# we could incorporate some kind of event detector in the customfeatureextractor\n",
                "\n",
                "class CustomFeatureExtractor(SequenceFeatureExtractor):\n",
                "    model_input_names = [\"input_values\"]\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        feature_size=1,\n",
                "        sampling_rate=32_000,\n",
                "        padding_value=0.0,\n",
                "        return_attention_mask=False\n",
                "    ):\n",
                "        # initialize sequencefeatureextractor\n",
                "        super().__init__(feature_size=feature_size, sampling_rate=sampling_rate, padding_value=padding_value)\n",
                "        self.return_attention_mask = return_attention_mask\n",
                "\n",
                "    def __call__(\n",
                "        self, \n",
                "        raw_audio,\n",
                "        padding = False, \n",
                "        max_length = None,\n",
                "        truncation = False, \n",
                "        return_tensors = None,\n",
                "        sampling_rate = None\n",
                "    ) -> BatchFeature:\n",
                "        \n",
                "        # control/check sampling rate \n",
                "        if self.sampling_rate is not None: \n",
                "            if sampling_rate != self.sampling_rate:\n",
                "                raise ValueError(\n",
                "                    f\"The model corresponding to this feature extractor: {self} was trained using a sampling rate of\"\n",
                "                    f\"{self.sampling_rate}. Make sure that the provided `raw_audio`input was sampled with\"\n",
                "                    f\"{self.sampling_rate} and not {sampling_rate}.\"\n",
                "                )\n",
                "        else:\n",
                "            print( \"It is strongly recommended to pass the ``sampling_rate`` argument to this function. \\\n",
                "                    Failing to do so can result in silent errors that might be hard to debug.\")\n",
                "        # check batch input\n",
                "        is_batched_numpy = isinstance(raw_audio, np.ndarray) and len(raw_audio.shape) > 1\n",
                "        is_batched = is_batched_numpy or (\n",
                "            isinstance(raw_audio, (list, tuple)) and (isinstance(raw_audio[0], (np.ndarray, tuple, list)))\n",
                "        )\n",
                "\n",
                "        if not is_batched:\n",
                "            raw_audio = [raw_audio]\n",
                "\n",
                "        encoded_inputs = BatchFeature({\"input_values\": raw_audio})\n",
                "\n",
                "        padded_inputs = self.pad(\n",
                "            encoded_inputs,\n",
                "            padding=padding,\n",
                "            max_length=max_length,\n",
                "            return_attention_mask=None,\n",
                "            truncation=truncation\n",
                "        )\n",
                "        # return_to_tensors comes from: transformers/birdset/transformers/feature_extraction_utils.py\n",
                "        if return_tensors is not None:\n",
                "            padded_inputs = padded_inputs.convert_to_tensors(return_tensors)\n",
                "                \n",
                "        return padded_inputs "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading cached processed dataset at /home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata5k_ogg_nodecode-de5164d492ad6e9e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c041687f9d2f3ce9.arrow\n",
                        "Loading cached processed dataset at /home/lukas/.cache/huggingface/datasets/DBD-research-group___parquet/DBD-research-group--na_metadata5k_ogg_nodecode-de5164d492ad6e9e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3273e49b4e01136d.arrow\n"
                    ]
                }
            ],
            "source": [
                "feature_extractor = CustomFeatureExtractor()\n",
                "\n",
                "def preprocess_function(samples):\n",
                "    audio_arrays = [x[\"array\"] for x in samples[\"audio\"]]\n",
                "    inputs = feature_extractor(\n",
                "        audio_arrays,\n",
                "        sampling_rate=feature_extractor.sampling_rate,\n",
                "        padding=True,\n",
                "        max_length=32_000*5,\n",
                "        truncation=True,\n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "    return inputs\n",
                "\n",
                "\n",
                "encoded_birdset = birdset5k_audio.map(\n",
                "    preprocess_function,\n",
                "    remove_columns=['audio'],\n",
                "    batched=True,\n",
                "    batch_size=100,\n",
                "    load_from_cache_file=True\n",
                ")\n",
                "\n",
                "# took ~14 mionutes?\n",
                "\n",
                "# truncate and pad"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1.381171792"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "encoded_birdset[\"train\"].data.nbytes /1e9"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "2.015389166"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "birdset5k_audio[\"train\"].data.nbytes /1e9"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['primary', 'input_values'],\n",
                            "        num_rows: 4316\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['primary', 'input_values'],\n",
                            "        num_rows: 1080\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "encoded_birdset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# important! otherwise, dataloader does not work\n",
                "encoded_birdset.set_format(\"np\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'primary': 12,\n",
                            " 'input_values': array([ 8.7311491e-11, -1.4551915e-10, -5.3842086e-10, ...,\n",
                            "        -6.6355248e-03, -6.7564198e-03, -3.9427751e-03], dtype=float32)}"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "encoded_birdset[\"train\"][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Dataset({\n",
                            "    features: ['primary', 'input_values'],\n",
                            "    num_rows: 4316\n",
                            "})"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "encoded_birdset[\"train\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataloader = DataLoader(\n",
                "    encoded_birdset[\"train\"],\n",
                "    batch_size=16,\n",
                "    shuffle=False,\n",
                "    num_workers=4,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'primary': tensor([12, 12, 37,  6, 29, 16, 35,  6, 12, 28, 15,  6,  3, 16, 38, 19]),\n",
                            " 'input_values': tensor([[ 8.7311e-11, -1.4552e-10, -5.3842e-10,  ..., -6.6355e-03,\n",
                            "          -6.7564e-03, -3.9428e-03],\n",
                            "         [-1.3824e-10,  2.1828e-11, -1.4916e-10,  ..., -6.9000e-03,\n",
                            "          -4.3055e-03,  1.6439e-03],\n",
                            "         [ 1.3097e-10, -3.2742e-10, -4.0018e-11,  ..., -2.4993e-03,\n",
                            "          -6.6736e-03, -5.9759e-03],\n",
                            "         ...,\n",
                            "         [-1.0516e-12, -1.1369e-13,  4.5475e-13,  ..., -2.9336e-02,\n",
                            "          -3.9038e-02, -4.6530e-02],\n",
                            "         [-3.9246e-06,  6.9001e-05,  1.1259e-04,  ..., -2.7581e-02,\n",
                            "          -1.6591e-02, -1.2605e-02],\n",
                            "         [ 2.5702e-06,  2.7131e-06,  2.9221e-06,  ..., -8.6000e-03,\n",
                            "          -1.3283e-02, -1.1424e-02]])}"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(dataloader))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 270/270 [00:00<00:00, 752.98it/s]\n"
                    ]
                }
            ],
            "source": [
                "for batch in tqdm(dataloader): \n",
                "    pass\n",
                "\n",
                "# takes 0.3seconds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 4316/4316 [00:00<00:00, 9957.35it/s] \n"
                    ]
                }
            ],
            "source": [
                "for instance in tqdm(encoded_birdset[\"train\"]):\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Without Mapping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass\n",
                "from typing import Any\n",
                "from transformers import BatchFeature\n",
                "\n",
                "@dataclass\n",
                "class CustomCollatorWithPadding:\n",
                "\n",
                "    feature_extractor: Any\n",
                "    padding: bool = True\n",
                "    truncation: bool = True\n",
                "    max_length: int = None\n",
                "    return_tensors: str = \"pt\"\n",
                "    preprocessed: bool=False\n",
                "\n",
                "    def __call__(self, batch):\n",
                "\n",
                "        # preprocessed means that the .map function was applied\n",
                "        # here, the feature extractor is only used for padding\n",
                "        if self.preprocessed:\n",
                "            batch = self.feature_extractor.pad(\n",
                "                batch,\n",
                "                padding=self.padding,\n",
                "                max_length=self.max_length,\n",
                "                truncation=self.truncation,\n",
                "                return_tensors=self.return_tensors,\n",
                "                return_attention_mask = None\n",
                "            )\n",
                "\n",
                "        # here, we first have to format the input and then pad it\n",
                "        # note that everything regarding resampling is not implemented here    \n",
                "        else:\n",
                "            audio_arrays = [x[\"audio\"][\"array\"] for x in batch]\n",
                "            labels = [x[\"primary\"] for x in batch]\n",
                "\n",
                "            # batch feature is just a dictionary\n",
                "            encoded_inputs = BatchFeature({\"input_values\": audio_arrays})\n",
                "            batch = {**encoded_inputs, \"labels\": labels}\n",
                "\n",
                "            batch = self.feature_extractor.pad(\n",
                "                batch,\n",
                "                padding=self.padding,\n",
                "                max_length=self.max_length,\n",
                "                truncation=self.truncation,\n",
                "                return_tensors=self.return_tensors,\n",
                "                return_attention_mask = None\n",
                "            )\n",
                "\n",
                "        if \"label\" in batch: \n",
                "            batch[\"labels\"] = batch[\"label\"]\n",
                "            del batch[\"label\"]\n",
                "\n",
                "        if \"target\" in batch:\n",
                "            batch[\"labels\"] = batch[\"target\"]\n",
                "            del batch[\"target\"]\n",
                "        \n",
                "        if \"primary\" in batch:\n",
                "            batch[\"labels\"] = batch[\"primary\"]\n",
                "            del batch[\"primary\"]\n",
                "\n",
                "        \n",
                "        return batch\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_extractor = CustomFeatureExtractor()\n",
                "dataloader = DataLoader(\n",
                "    birdset5k_audio[\"train\"],\n",
                "    collate_fn=CustomCollatorWithPadding(\n",
                "        feature_extractor,\n",
                "        padding='longest',\n",
                "        return_tensors=\"pt\",\n",
                "        truncation=False        \n",
                "    ),\n",
                "    batch_size=16,\n",
                "    shuffle=False,\n",
                "    num_workers=4,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'input_values': tensor([[ 8.7311e-11, -1.4552e-10, -5.3842e-10,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [-1.3824e-10,  2.1828e-11, -1.4916e-10,  ...,  0.0000e+00,\n",
                            "          0.0000e+00, -1.8190e-12],\n",
                            "        [ 1.3097e-10, -3.2742e-10, -4.0018e-11,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        ...,\n",
                            "        [-1.0516e-12, -1.1369e-13,  4.5475e-13,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [-3.9246e-06,  6.9001e-05,  1.1259e-04,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00],\n",
                            "        [ 2.5702e-06,  2.7131e-06,  2.9221e-06,  ...,  0.0000e+00,\n",
                            "          0.0000e+00,  0.0000e+00]]), 'labels': tensor([12, 12, 37,  6, 29, 16, 35,  6, 12, 28, 15,  6,  3, 16, 38, 19])}"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(dataloader))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 270/270 [03:26<00:00,  1.31it/s]\n"
                    ]
                }
            ],
            "source": [
                "for batch in tqdm(dataloader):\n",
                "    pass\n",
                "\n",
                "# took 3 minutes with loading and padding (without .map feature extraction!)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dal-toolbox",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}