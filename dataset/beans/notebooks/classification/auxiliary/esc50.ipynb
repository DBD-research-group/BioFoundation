{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the BEANS esc50 recordings to HF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download the recordings the way BEANS do it on their [GitHub](https://github.com/earthspecies/beans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will navigate into the mounted data_birdset folder to download the temporary files from the Repo their and install wget & unzip as they are not on the university bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data_birdset/beans\n",
      "/workspace/data_birdset/beans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.21.2-2ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-26ubuntu3.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "%cd '../../../../../data_birdset/beans'\n",
    "!pwd\n",
    "!sudo apt install wget\n",
    "!sudo apt install unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will run their script to download the metadata and recordings to have the same splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Their script:\n",
    "import pandas as pd\n",
    "from plumbum import local\n",
    "\n",
    "target_dir = \"data/esc50\"\n",
    "\n",
    "git = local[\"git\"]\n",
    "git[\"clone\", \"https://github.com/karolpiczak/ESC-50.git\", target_dir]()\n",
    "\n",
    "df = pd.read_csv(f\"{target_dir}/meta/esc50.csv\")\n",
    "\n",
    "\n",
    "def convert(row):\n",
    "    new_row = pd.Series(\n",
    "        {\n",
    "            \"path\": f\"data/esc50/audio/{row['filename']}\",\n",
    "            \"label\": row[\"target\"],\n",
    "            \"fold\": row[\"fold\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return new_row\n",
    "\n",
    "\n",
    "df = df.apply(convert, axis=1)\n",
    "\n",
    "\n",
    "def _get_fold(row):\n",
    "    return int(row[\"fold\"])\n",
    "    # return int(row['filename'][0])\n",
    "\n",
    "\n",
    "df_train = df[df.apply(lambda r: _get_fold(r) <= 3, axis=1)]\n",
    "df_train_low = df[df.apply(lambda r: _get_fold(r) == 1, axis=1)]\n",
    "df_valid = df[df.apply(lambda r: _get_fold(r) == 4, axis=1)]\n",
    "df_test = df[df.apply(lambda r: _get_fold(r) == 5, axis=1)]\n",
    "\n",
    "df_train.to_csv(f\"{target_dir}/meta/esc50.train.csv\")\n",
    "df_train_low.to_csv(f\"{target_dir}/meta/esc50.train-low.csv\")\n",
    "df_valid.to_csv(f\"{target_dir}/meta/esc50.valid.csv\")\n",
    "df_test.to_csv(f\"{target_dir}/meta/esc50.test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert to HF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'path': {'path': 'data/esc50/audio/1-100032-A-0.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sample_rate': 44100}, 'label': 0, 'fold': 1}\n",
      "{'Unnamed: 0': 1200, 'path': {'path': 'data/esc50/audio/4-102844-A-49.wav', 'array': array([ 0.0302124 ,  0.0458374 ,  0.05664062, ..., -0.04403687,\n",
      "       -0.05728149, -0.05892944]), 'sample_rate': 44100}, 'label': 49, 'fold': 4}\n",
      "{'Unnamed: 0': 1600, 'path': {'path': 'data/esc50/audio/5-103415-A-2.wav', 'array': array([0.16473389, 0.17315674, 0.17971802, ..., 0.26345825, 0.1300354 ,\n",
      "       0.03866577]), 'sample_rate': 44100}, 'label': 2, 'fold': 5}\n",
      "{'Unnamed: 0': 0, 'path': {'path': 'data/esc50/audio/1-100032-A-0.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sample_rate': 44100}, 'label': 0, 'fold': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dataset(split_name):\n",
    "    df = pd.read_csv(f\"data/esc50/meta/esc50.{split_name}.csv\")\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset = dataset.cast_column(\"path\", Audio())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "splits = [\"train\", \"train-low\", \"valid\", \"test\"]\n",
    "datasets = {split: load_dataset(split) for split in splits}\n",
    "datasets[\"train_low\"] = datasets.pop(\n",
    "    \"train-low\"\n",
    ")  # Rename split from train-low to train_low as HF does not accept -\n",
    "for split, dataset in datasets.items():\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Upload the datasets to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c9d80d118b43d7b49a6ab7af3a9ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07a124b4a154658af60c421defa32f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bbcf05400845ac810b55657d485fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1c9963f659473388fce565273446f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b07d12319fd464c9b13686ff8dc2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3877b54e1b49d5a49c079a09aad13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a205e48436ee4b8e8c20626f7e7bdfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5498400bef40dabde613fd90cc34c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289479713fed44cca967c07a53c2ebaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/388 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b817d821dd4c28a5c622d953edbae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c92092290d4771812973f23c558b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f2a8d93509497baacdd92182848dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a177b9a9e6041b48f3c6130ff8c7fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9849efdf6c294f8f879d0d3af2f7c57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de095a3524d4631bf1c453b2507eeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adb44fae2d247528dc93d8c536e83ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542930866ac24b20848380d7f9988fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/595 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in datasets.items():\n",
    "    dataset.push_to_hub(\"DBD-research-group/beans_esc50\", split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Download the dataset from HF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all splits from the hub. Even when specifying a specific split it still downloads everything! Use `streaming=True` and `cache_dir='...'` for shorter loading times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7378437bb9d45dc962e1b25e384ca7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 399M/399M [00:39<00:00, 10.0MB/s] \n",
      "Downloading data: 100%|██████████| 399M/399M [00:37<00:00, 10.7MB/s] \n",
      "Downloading data: 100%|██████████| 402M/402M [00:35<00:00, 11.3MB/s] \n",
      "Downloading data: 100%|██████████| 396M/396M [00:45<00:00, 8.66MB/s] \n",
      "Downloading data: 100%|██████████| 406M/406M [00:45<00:00, 8.84MB/s] \n",
      "Downloading data: 100%|██████████| 397M/397M [00:40<00:00, 9.72MB/s] \n",
      "Downloading data: 100%|██████████| 287M/287M [00:25<00:00, 11.4MB/s] \n",
      "Downloading data: 100%|██████████| 313M/313M [00:29<00:00, 10.5MB/s] \n",
      "Downloading data: 100%|██████████| 24.7M/24.7M [00:02<00:00, 9.70MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33a9d63a3d749d89ffb7f44c36acbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84843 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce18a65312945968de365c9a4b11bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/9981 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c7367e64b5436b94055f4e3088e20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df2a79c467f45d5a4d48e17db083084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_low split:   0%|          | 0/849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# dataset = load_dataset(path='DBD-research-group/beans_esc50', split='train_low')\n",
    "dataset: DatasetDict = load_dataset(\n",
    "    name=\"default\", path=\"DBD-research-group/beans_esc50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 84843\n",
      "Number of distinct classes: 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'path', 'label'],\n",
       "        num_rows: 84843\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Unnamed: 0', 'path', 'label'],\n",
       "        num_rows: 9981\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'path', 'label'],\n",
       "        num_rows: 11005\n",
       "    })\n",
       "    train_low: Dataset({\n",
       "        features: ['Unnamed: 0', 'path', 'label'],\n",
       "        num_rows: 849\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of samples and number of distinct classes\n",
    "print(f\"Number of samples: {len(dataset['train'])}\")\n",
    "print(f\"Number of distinct classes: {len(dataset['train'].unique('label'))}\")\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}